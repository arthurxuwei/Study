{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from scipy.stats import poisson\n",
    "from stochastic_processes.distribution import Categorical, FiniteDistribution, SampledDistribution, Constant\n",
    "from stochastic_processes.policy import DeterministicPolicy, Policy, FiniteDeterministicPolicy\n",
    "from stochastic_processes.markov_process import FiniteMarkovProcess, MarkovRewardProcess, FiniteMarkovRewardProcess, \\\n",
    "    NonTerminal, State\n",
    "from stochastic_processes.markov_decision_process import MarkovDecisionProcess, FiniteMarkovDecisionProcess\n",
    "from typing import Mapping, Dict, Tuple, Iterator\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class InventoryState:\n",
    "    on_hand: int\n",
    "    on_order: int\n",
    "\n",
    "    def inventory_position(self) -> int:\n",
    "        return self.on_hand + self.on_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInventoryMPFinite(FiniteMarkovProcess[InventoryState]):\n",
    "    def __init__(self, capacity: int, poisson_lambda: float) -> None:\n",
    "        self.capacity = capacity\n",
    "        self.poission_lambda = poisson_lambda\n",
    "        self.poission_distr = poisson(poisson_lambda)\n",
    "        super().__init__(self.get_transition_map())\n",
    "    \n",
    "    def get_transition_map(self) -> Mapping[InventoryState, FiniteDistribution[InventoryState]]:\n",
    "        d: Dict[InventoryState, Categorical[InventoryState]] = {}\n",
    "        for alpha in range(self.capacity + 1):\n",
    "            for beta in range(self.capacity + 1 - alpha):\n",
    "                state = InventoryState(alpha, beta)\n",
    "                ip = state.inventory_position()\n",
    "                beta1 = self.capacity - ip\n",
    "                state_probs_map: Mapping[InventoryState, float] = {\n",
    "                    InventoryState(ip - i, beta1) : (self.poission_distr.pmf(i) if i < ip else 1 - self.poission_distr.cdf(ip - 1))\n",
    "                    for i in range(ip + 1)\n",
    "                }\n",
    "                d[InventoryState(alpha, beta)] = Categorical(state_probs_map)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From State InventoryState(on_hand=0, on_order=0):\n",
      "To State InventoryState(on_hand=0, on_order=2) with Probability 1.000\n",
      "From State InventoryState(on_hand=0, on_order=1):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=0, on_order=2):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=1, on_order=0):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=1, on_order=1):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=2, on_order=0):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "si_mp = SimpleInventoryMPFinite(capacity=2, poisson_lambda=1.0)\n",
    "print(si_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInventoryMRP(MarkovRewardProcess[InventoryState]):\n",
    "    def __init__(self, capacity: int, poisson_lambda: float, holding_cost: float, stockout_cost: float) -> None:\n",
    "        self.capacity = capacity\n",
    "        self.poisson_lambda = poisson_lambda\n",
    "        self.holding_cost = holding_cost\n",
    "        self.stockout_cost = stockout_cost\n",
    "    \n",
    "    def transition_reward(self, state: NonTerminal[InventoryState]) -> SampledDistribution[Tuple[State[InventoryState], float]]:\n",
    "        def sample_next_state_reward(state=state) -> Tuple[State[InventoryState], float]:\n",
    "            demand_sample = np.random.poisson(self.poisson_lambda)\n",
    "            ip = state.state.inventory_position()\n",
    "            next_state = InventoryState(max(ip - demand_sample, 0), max(self.capacity - ip, 0))\n",
    "            reward = -self.holding_cost * state.state.on_hand - self.stockout_cost * max(demand_sample - ip , 0)\n",
    "            return NonTerminal(next_state), reward\n",
    "        return SampledDistribution(sample_next_state_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_mrp = SimpleInventoryMRP(capacity=2, poisson_lambda=1.0, holding_cost=1.0, stockout_cost=5.0)\n",
    "t = si_mrp.transition_reward(Categorical({NonTerminal(InventoryState(0, 0)):1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInventoryMRPFinite(FiniteMarkovRewardProcess[InventoryState]):\n",
    "    def __init__(self, capacity: int, poisson_lambda: float, holding_cost: float, stockout_cost: float):\n",
    "        self.capacity = capacity\n",
    "        self.poisson_lambda = poisson_lambda\n",
    "        self.holding_cost = holding_cost\n",
    "        self.stockout_cost = stockout_cost\n",
    "        self.poisson_distr = poisson(poisson_lambda)\n",
    "        super().__init__(self.get_transition_reward_map())\n",
    "\n",
    "    def get_transition_reward_map(self) -> Mapping[InventoryState, FiniteDistribution[Tuple[InventoryState, float]]]:\n",
    "        d = {}\n",
    "        for alpha in range(self.capacity + 1):\n",
    "            for beta in range(self.capacity + 1 - alpha):\n",
    "                state = InventoryState(alpha, beta)\n",
    "                ip = state.inventory_position()\n",
    "                beta1 = self.capacity - ip\n",
    "                base_reward = - self.holding_cost * state.on_hand\n",
    "                sr_probs_map = {(InventoryState(ip - i, beta1),  base_reward) : self.poisson_distr.pmf(i) for i in range(ip)}\n",
    "                probability = 1 - self.poisson_distr.cdf(ip - 1)\n",
    "                reward = base_reward - self.stockout_cost * (probability * (self.poisson_lambda - ip) + ip * self.poisson_distr.pmf(ip))\n",
    "                sr_probs_map[(InventoryState(0, beta1), reward)] = probability\n",
    "                d[state] = Categorical(sr_probs_map)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Map\n",
      "--------------\n",
      "From State InventoryState(on_hand=0, on_order=0):\n",
      "To State InventoryState(on_hand=0, on_order=2) with Probability 1.000\n",
      "From State InventoryState(on_hand=0, on_order=1):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=0, on_order=2):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=1, on_order=0):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=1, on_order=1):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=2, on_order=0):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "\n",
      "Transition Reward Map\n",
      "---------------------\n",
      "From State InventoryState(on_hand=0, on_order=0):\n",
      "To State InventoryState(on_hand=0, on_order=2) with Probability 1.000\n",
      "From State InventoryState(on_hand=0, on_order=1):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=0, on_order=2):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=1, on_order=0):\n",
      "To State InventoryState(on_hand=1, on_order=1) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=1) with Probability 0.632\n",
      "From State InventoryState(on_hand=1, on_order=1):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "From State InventoryState(on_hand=2, on_order=0):\n",
      "To State InventoryState(on_hand=2, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=1, on_order=0) with Probability 0.368\n",
      "To State InventoryState(on_hand=0, on_order=0) with Probability 0.264\n",
      "\n",
      "Stationary Distribution\n",
      "-----------------------\n",
      "{InventoryState(on_hand=1, on_order=1): 0.162,\n",
      " InventoryState(on_hand=1, on_order=0): 0.162,\n",
      " InventoryState(on_hand=0, on_order=1): 0.279,\n",
      " InventoryState(on_hand=2, on_order=0): 0.162,\n",
      " InventoryState(on_hand=0, on_order=2): 0.117,\n",
      " InventoryState(on_hand=0, on_order=0): 0.117}\n",
      "\n",
      "Reward Function\n",
      "---------------\n",
      "{NonTerminal(state=InventoryState(on_hand=0, on_order=2)): -0.274,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=0)): -10.0,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=0)): -3.325,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=1)): -1.274,\n",
      " NonTerminal(state=InventoryState(on_hand=2, on_order=0)): -2.274,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=1)): -2.325}\n",
      "\n",
      "Value Function\n",
      "--------------\n",
      "{NonTerminal(state=InventoryState(on_hand=0, on_order=2)): -28.345,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=0)): -35.511,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=0)): -28.932,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=1)): -29.345,\n",
      " NonTerminal(state=InventoryState(on_hand=2, on_order=0)): -30.345,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=1)): -27.932}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_capacity = 2\n",
    "user_poisson_lambda = 1.0\n",
    "user_holding_cost = 1.0\n",
    "user_stockout_cost = 10.0\n",
    "\n",
    "user_gamma = 0.9\n",
    "\n",
    "si_mrp = SimpleInventoryMRPFinite(user_capacity, user_poisson_lambda, user_holding_cost, user_stockout_cost)\n",
    "\n",
    "print(\"Transition Reward Map\")\n",
    "print(\"---------------------\")\n",
    "print(si_mrp)\n",
    "\n",
    "print(\"Stationary Distribution\")\n",
    "print(\"-----------------------\")\n",
    "si_mrp.display_stationary_distribution()\n",
    "print()\n",
    "\n",
    "print(\"Reward Function\")\n",
    "print(\"---------------\")\n",
    "si_mrp.display_reward_function()\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Value Function\")\n",
    "print(\"--------------\")\n",
    "si_mrp.display_value_function(gamma=user_gamma)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInventoryDeterministicPolicy(DeterministicPolicy[InventoryState, int]):\n",
    "    def __init__(self, reorder_point: int) -> None:\n",
    "        self.reorder_point = reorder_point\n",
    "\n",
    "        def action_for(s: InventoryState) -> int:\n",
    "            return max(self.reorder_point - s.inventory_position(), 0)\n",
    "        \n",
    "        super().__init__(action_for)\n",
    "\n",
    "class SimpleInventoryStochasticPolicy(Policy[InventoryState, int]):\n",
    "    def __init__(self, reorder_point_poisson_mean: float) -> None:\n",
    "        self.reorder_point_poisson_mean = reorder_point_poisson_mean\n",
    "\n",
    "    def act(self, state: NonTerminal[InventoryState]) -> SampledDistribution[int]:\n",
    "        def action_func(state=state) -> int:\n",
    "            reorder_point_sample: int = np.random.poisson(self.reorder_point_poisson_mean)\n",
    "            return max(reorder_point_sample - state.state.inventory_position(), 0)\n",
    "        return SampledDistribution(action_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimpleInventoryMDPNoCap(MarkovDecisionProcess[InventoryState, int]):\n",
    "    poisson_lambda: float\n",
    "    holding_cost: float\n",
    "    stockout_cost: float\n",
    "\n",
    "    def step(self, state: NonTerminal[InventoryState], order: int) -> SampledDistribution[Tuple[State[InventoryState], float]]:\n",
    "        def sample_next_state_reward(state=state, order=order) -> Tuple[State[InventoryState], float]:\n",
    "            demand_sample = np.random.poisson(self.poisson_lambda)\n",
    "            ip = state.state.inventory_position()\n",
    "            next_state = InventoryState(max(ip - demand_sample, 0), order)\n",
    "            reward = - self.holding_cost * state.state.on_hand - self.stockout_cost * max(demand_sample - ip, 0)\n",
    "            return NonTerminal(next_state), reward\n",
    "        return SampledDistribution(sample_next_state_reward)\n",
    "\n",
    "    def action(self, state: NonTerminal[InventoryState]) -> Iterator[int]:\n",
    "        return itertools.count(start=0, step=1)\n",
    "\n",
    "    def fraction_of_days_oos(self, policy: Policy[InventoryState, int], time_steps: int, num_traces: int) -> float:\n",
    "        impl_mrp = self.apply_policy(policy)\n",
    "        count = 0\n",
    "        high_fractile = int(poisson(self.poisson_lambda).ppf(0.98))\n",
    "        start = random.choice([InventoryState(i, 0) for i in range(high_fractile + 1)])\n",
    "\n",
    "        for _ in range(num_traces):\n",
    "            steps = itertools.islice(impl_mrp.simulate_reward(Constant(NonTerminal(start))), time_steps)\n",
    "            for step in steps:\n",
    "                if step.reward < -self.holding_cost * step.state.state.on_hand:\n",
    "                    count += 1\n",
    "        \n",
    "        return float(count) / (time_steps * num_traces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic Policy yields 1.91% of Out-Of-Stock days\n"
     ]
    }
   ],
   "source": [
    "user_poisson_lambda = 2.0\n",
    "user_holding_cost = 1.0\n",
    "user_stockout_cost = 10.0\n",
    "\n",
    "user_reorder_point = 8\n",
    "user_reorder_point_poisson_mean = 8.0\n",
    "\n",
    "user_time_steps = 1000\n",
    "user_num_traces = 1000\n",
    "\n",
    "si_mdp_nocap = SimpleInventoryMDPNoCap(poisson_lambda=user_poisson_lambda,\n",
    "                                        holding_cost=user_holding_cost,\n",
    "                                        stockout_cost=user_stockout_cost)\n",
    "\n",
    "si_dp = SimpleInventoryDeterministicPolicy(reorder_point=user_reorder_point)\n",
    "\n",
    "oos_frac_dp = si_mdp_nocap.fraction_of_days_oos(policy=si_dp,\n",
    "                                                time_steps=user_time_steps,\n",
    "                                                num_traces=user_num_traces)\n",
    "print(\n",
    "    f\"Deterministic Policy yields {oos_frac_dp * 100:.2f}%\"\n",
    "    + \" of Out-Of-Stock days\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvOrderMapping = Mapping[InventoryState, Mapping[int, Categorical[Tuple[InventoryState, float]]]]\n",
    "\n",
    "class SimpleInventoryMDPCap(FiniteMarkovDecisionProcess[InventoryState, int]):\n",
    "    def __init__(self, capacity: int, poisson_lambda: float, holding_cost: float, stockout_cost: float) -> None:\n",
    "        self.capacity = capacity\n",
    "        self.poisson_lambda = poisson_lambda\n",
    "        self.holding_cost = holding_cost\n",
    "        self.stockout_cost = stockout_cost\n",
    "        self.poisson_distr = poisson(poisson_lambda)\n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> InvOrderMapping:\n",
    "        d = {}\n",
    "        for alpha in range(self.capacity + 1):\n",
    "            for beta in range(self.capacity + 1 - alpha):\n",
    "                state = InventoryState(alpha, beta)\n",
    "                ip = state.inventory_position()\n",
    "                base_reward = -self.holding_cost * alpha\n",
    "                d1 = {}\n",
    "                for order in range(self.capacity - ip + 1):\n",
    "                    sr_probs_dict = {(InventoryState(ip - i, order), base_reward): self.poisson_distr.pmf(i) for i in range(ip)}\n",
    "                    probability = 1 - self.poisson_distr.cdf(ip - 1)\n",
    "                    reward = base_reward - self.stockout_cost * (probability * (self.poisson_lambda - ip) + ip * self.poisson_distr.pmf(ip))\n",
    "                    sr_probs_dict[(InventoryState(0, order), reward)] = probability\n",
    "                    d1[order] = Categorical(sr_probs_dict)\n",
    "                d[state] = d1\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class SimpleInventoryMDPCap with abstract method action",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arthur.xw/economics/inventory_example.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.81.152.16/home/arthur.xw/economics/inventory_example.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m user_holding_cost \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.81.152.16/home/arthur.xw/economics/inventory_example.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m user_stockout_cost \u001b[39m=\u001b[39m \u001b[39m10.0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.81.152.16/home/arthur.xw/economics/inventory_example.ipynb#ch0000011vscode-remote?line=5'>6</a>\u001b[0m si_mdp \u001b[39m=\u001b[39m SimpleInventoryMDPCap(user_capacity, user_poisson_lambda, user_holding_cost, user_stockout_cost)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.81.152.16/home/arthur.xw/economics/inventory_example.ipynb#ch0000011vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMDP Transition Map\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.81.152.16/home/arthur.xw/economics/inventory_example.ipynb#ch0000011vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class SimpleInventoryMDPCap with abstract method action"
     ]
    }
   ],
   "source": [
    "user_capacity = 2\n",
    "user_poisson_lambda = 1.0\n",
    "user_holding_cost = 1.0\n",
    "user_stockout_cost = 10.0\n",
    "\n",
    "si_mdp = SimpleInventoryMDPCap(user_capacity, user_poisson_lambda, user_holding_cost, user_stockout_cost)\n",
    "print(\"MDP Transition Map\")\n",
    "print(\"------------------\")\n",
    "print(si_mdp)\n",
    "fdp = FiniteDeterministicPolicy({\n",
    "    InventoryState(alpha, beta): user_capacity - (alpha + beta)\n",
    "    for alpha in range(user_capacity + 1) \n",
    "    for beta in range(user_capacity + 1 - alpha)\n",
    "})\n",
    "print(\"Deterministic Policy Map\")\n",
    "print(\"------------------------\")\n",
    "print(fdp)\n",
    "implied_mrp = si_mdp.apply_finite_policy(fdp)\n",
    "print(\"Implied MP Transition Map\")\n",
    "print(\"--------------\")\n",
    "print(FiniteMarkovProcess(\n",
    "    {s.state: Categorical({s1.state: p for s1, p in v.table().items()})\n",
    "        for s, v in implied_mrp.transition_map.items()}\n",
    "))\n",
    "print(\"Implied MRP Transition Reward Map\")\n",
    "print(\"---------------------\")\n",
    "print(implied_mrp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5329c6d7c2972a4b06ba848ee0ca41a4d42e7f79311b3904fab66a970dd71896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
